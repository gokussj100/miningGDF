{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2921b8d1",
   "metadata": {},
   "source": [
    "<center><img src=\"https://i.imgur.com/zRrFdsf.png\" width=\"700\"></center>\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "<a target=\"_blank\" href=\"https://colab.research.google.com/github/CienciaDeDatosEspacial/code_and_data/blob/main/Mining_GeoDFs.ipynb\">\n",
    "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
    "</a>\n",
    "\n",
    "# Mining your GeoDataFrame\n",
    "\n",
    "This final session will need all the files from the zipped folder \"miningGDF\" available [here](https://drive.google.com/drive/folders/1aLZXirKg0AeEeY7CRpYCOjVgYv2Dj2Hx?usp=sharing). Download and unzip that folder, which has two folders (map and data).\n",
    "\n",
    "First, let's open the _brazilMaps_5641.gpkg_ map file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d035f11e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from  fiona import listlayers\n",
    "import os\n",
    "\n",
    "brazilMaps=os.path.join('maps','brazilMaps_5641.gpkg')\n",
    "\n",
    "#layers in maps\n",
    "listlayers(brazilMaps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71bca363",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading in the data:\n",
    "import os\n",
    "import geopandas as gpd\n",
    "\n",
    "states=gpd.read_file(brazilMaps,layer='states')\n",
    "municipalities=gpd.read_file(brazilMaps,layer='municipalities')\n",
    "airports=gpd.read_file(brazilMaps,layer='airports')\n",
    "rivers=gpd.read_file(brazilMaps,layer='rivers')\n",
    "border=gpd.read_file(brazilMaps,layer='border')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c567126e",
   "metadata": {},
   "source": [
    "Now, we are going to add more data. In this [link](https://msi.nga.mil/Publications/WPI) we find the  World Port Index (Pub 150), which contains several data on major ports and terminals world-wide. Read in the **UpdatedPub150.csv** file also from zipped folder:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea0d908f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "\n",
    "\n",
    "portsFile=os.path.join('data','UpdatedPub150.csv')\n",
    "\n",
    "infoseaports=pd.read_csv(portsFile)\n",
    "#columns available (so many)\n",
    "infoseaports.columns.to_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ae0e92a",
   "metadata": {},
   "source": [
    "Let's do some preprocessing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42dc537e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#rename\n",
    "infoseaports.rename(columns={'Main Port Name':'portName'},inplace=True)\n",
    "#subset\n",
    "infoseaports=infoseaports.loc[:,['portName', 'Country Code','Latitude', 'Longitude']]\n",
    "\n",
    "# we have now\n",
    "infoseaports.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c28b10c1-98ef-49be-9f7e-9cff0f6b91fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# some rows\n",
    "infoseaports.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "810f28f2",
   "metadata": {},
   "source": [
    "It looks ready to become a spatial object (GDF of points):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16d2a73e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#spatial points (unprojected)\n",
    "seaports=gpd.GeoDataFrame(data=infoseaports.copy(),\n",
    "                           geometry=gpd.points_from_xy(infoseaports.Longitude,\n",
    "                                                       infoseaports.Latitude), \n",
    "                          crs=4326)# notice it is unprojected\n",
    "\n",
    "# subset:\n",
    "seaports_bra=seaports[seaports['Country Code']=='Brazil'].copy()\n",
    "\n",
    "# reset indexes\n",
    "seaports_bra.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# reprojecting\n",
    "seaports_bra_5641=seaports_bra.to_crs(5641) # projected crs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5afed0d",
   "metadata": {},
   "source": [
    "Let me plot seaports along with the airports (only large ones) we have:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efd8f3eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# subsetting\n",
    "largeAirports=airports[airports['kind']=='large_airport'] #can't use \"airports.type\"\n",
    "largeAirports.reset_index(drop=True, inplace=True)\n",
    "\n",
    "#plotting\n",
    "base=largeAirports.plot(color='red',marker=\"^\")\n",
    "seaports_bra_5641.plot(ax=base,alpha=0.5,markersize=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e33e90a3",
   "metadata": {},
   "source": [
    "# Part I. Distance between spatial objects\n",
    "\n",
    "## Distance between points\n",
    "\n",
    "The easiest way to understand distance is to compute how far two coordinates are from each other.\n",
    "\n",
    "You have the seaports:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40daaf71",
   "metadata": {},
   "outputs": [],
   "source": [
    "seaports_bra_5641.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a923d850",
   "metadata": {},
   "source": [
    "..and the large airports:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b3058d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "largeAirports.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63843300",
   "metadata": {},
   "source": [
    "If both GDFs have the same projected CRS, we can use the **distance** function. In this case, just two selected points:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4c53d18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# distance between 'Guarulhos' and 'Dtse / Gegua Oil Terminal' in km\n",
    "largeAirports.iloc[0].geometry.distance(seaports_bra_5641.iloc[0].geometry)/1000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e38446d9",
   "metadata": {},
   "source": [
    "What about computing all possible distances between those GDFs?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61a86921",
   "metadata": {},
   "outputs": [],
   "source": [
    "#try 1: default\n",
    "seaports_bra_5641.geometry.apply\\\n",
    "(lambda g: largeAirports.geometry.distance(g)/1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dde1d24e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# try 2: see names (change indexes)\n",
    "\n",
    "seaports_bra_5641.set_index('portName').geometry.apply\\\n",
    "(lambda g: largeAirports.set_index('name').geometry.distance(g)/1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0936bad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#try 3: reorder previous output\n",
    "\n",
    "seaports_bra_5641.set_index('portName').geometry.apply\\\n",
    "(lambda g: largeAirports.set_index('name').geometry.distance(g)/1000).\\\n",
    "sort_index(axis=0).sort_index(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c02e6be",
   "metadata": {},
   "source": [
    "Let's keep the last one:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d2f0b5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "distanceMatrixKM_sea_air= seaports_bra_5641.set_index('portName').geometry.apply\\\n",
    "                          (lambda g: largeAirports.set_index('name').geometry.distance(g)/1000).\\\n",
    "                          sort_index(axis=0).sort_index(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "481b14df",
   "metadata": {},
   "source": [
    "This a data frame (pandas), and the names of the facilities are row and column indexes. This is useful this way:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d023731",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the mean distance from a seaport to all the large airports (sorted)\n",
    "distanceMatrixKM_sea_air.mean(axis=1).sort_values(ascending=True) #axis=0?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a58d83a",
   "metadata": {},
   "source": [
    "Let's compute more stats:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a565ab8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "SomeStats=pd.DataFrame()\n",
    "SomeStats['mean']=distanceMatrixKM_sea_air.mean(axis=1)\n",
    "SomeStats['min']=distanceMatrixKM_sea_air.min(axis=1)\n",
    "SomeStats['max']=distanceMatrixKM_sea_air.max(axis=1)\n",
    "\n",
    "# see some\n",
    "SomeStats.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a343ceec",
   "metadata": {},
   "source": [
    "We can also use **idxmax** to get the particular locations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ce11850",
   "metadata": {},
   "outputs": [],
   "source": [
    "# farthest airport to each seaport\n",
    "distanceMatrixKM_sea_air.idxmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab247b61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# farthest seaport to each airport\n",
    "distanceMatrixKM_sea_air.idxmax(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d1014f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# closest airport to each seaport\n",
    "distanceMatrixKM_sea_air.idxmin(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4721bc58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# closest seaport to each airport\n",
    "distanceMatrixKM_sea_air.idxmin(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcd7444b-7180-4f2d-9082-e22125534587",
   "metadata": {},
   "source": [
    "### Exercises Part I\n",
    "\n",
    "<div class=\"alert-warning\">\n",
    "    \n",
    "Exercises 1,2,3,4 for this part must read you data from GitHub links, and the coding and results must be published using GitHub Pages\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7442ed0f-f773-4371-bc84-f7ffd81b7c85",
   "metadata": {},
   "source": [
    "### Exercise 1\n",
    "\n",
    "<div class=\"alert-success\">\n",
    "    \n",
    "1. Use two maps of points.\n",
    "\n",
    "2. Compute the distance matrix for both maps.\n",
    "\n",
    "3. Select one row of the distance matrix, and plot the two points with the minimal distance on top of the country of your choosing.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cceb84e",
   "metadata": {},
   "source": [
    "## Distance between line and point"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c4afe9d",
   "metadata": {},
   "source": [
    "Let's take a look at the rivers we have:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8c4ccd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "rivers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c57145a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#keep one:\n",
    "\n",
    "rivers[rivers.NAME.str.contains('Grande')]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67e02737",
   "metadata": {},
   "source": [
    "You can see that distance works between these two elements:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "874c38f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# distance from each airport to Rio Grande\n",
    "rivers[rivers.NAME.str.contains('Grande')].iloc[0].geometry.distance(largeAirports.set_index('name').geometry)/1000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a669e18",
   "metadata": {},
   "source": [
    "Based on what we did previously, let's compute all the distances:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be3f7a01",
   "metadata": {},
   "outputs": [],
   "source": [
    "distanceMatrixKM_riv_air=rivers.set_index('NAME').geometry.apply\\\n",
    "(lambda g: largeAirports.set_index('name').geometry.distance(g)/1000).\\\n",
    "sort_index(axis=0).sort_index(axis=1)\n",
    "distanceMatrixKM_riv_air"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cf3dafa",
   "metadata": {},
   "source": [
    "Here, we see one row (river), that tells the distance to each column (large airport):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b23b4d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "distanceMatrixKM_riv_air.loc['Rio Grande, South America'].sort_values()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48194e60",
   "metadata": {},
   "source": [
    "Let's try a simple plot of the river and the airports:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0642c01",
   "metadata": {},
   "outputs": [],
   "source": [
    "base=largeAirports.explore(color='red',marker_kwds=dict(radius=10))\n",
    "rivers[rivers.NAME.str.contains('Grande')].explore(m=base)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2211781a",
   "metadata": {},
   "source": [
    "Now, let's focus on the rivers that belong to a system:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0cb47c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "rivers[~rivers.SYSTEM.isna()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4186d59d",
   "metadata": {},
   "source": [
    "Let's dissolve the ones that belong to a system into a multiline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1796bcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "systems=rivers.dissolve(by='SYSTEM')\n",
    "systems"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22a63e87",
   "metadata": {},
   "source": [
    "Let's do some basic formatting:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4e139d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# format the GDF:\n",
    "\n",
    "systems.reset_index(drop=False,inplace=True)\n",
    "systems.drop(columns='NAME',inplace=True)\n",
    "\n",
    "# we have\n",
    "systems"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e8f39a4",
   "metadata": {},
   "source": [
    "Another distance matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b69142db",
   "metadata": {},
   "outputs": [],
   "source": [
    "distanceMatrixKM_sys_air=systems.set_index('SYSTEM').geometry.apply\\\n",
    "(lambda g: largeAirports.set_index('name').geometry.distance(g)/1000).\\\n",
    "sort_index(axis=0).sort_index(axis=1)\n",
    "\n",
    "distanceMatrixKM_sys_air"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db17f599",
   "metadata": {},
   "source": [
    "This time, let me get all the minimum distances:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74f986d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "mins=distanceMatrixKM_sys_air.idxmin(axis=\"columns\") # same as axis=1\n",
    "mins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43faa293",
   "metadata": {},
   "outputs": [],
   "source": [
    "# one of them\n",
    "mins.iloc[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1e10c68",
   "metadata": {},
   "source": [
    "Let's see now:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5690879",
   "metadata": {},
   "outputs": [],
   "source": [
    "base=systems.explore()\n",
    "# the closest\n",
    "largeAirports[largeAirports.name.isin(mins)].explore(m=base,color='red',marker_kwds=dict(radius=10))\n",
    "# NOT the closest\n",
    "largeAirports[~largeAirports.name.isin(mins)].explore(m=base,color='blue',marker_kwds=dict(radius=5))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77fb93ce-efb1-4e1a-b1cb-d1da31be655b",
   "metadata": {},
   "source": [
    "### Exercise 2\n",
    "\n",
    "<div class=\"alert-success\">\n",
    "    \n",
    "1. Use a map of points and a map of lines.\n",
    "\n",
    "2. Compute the distance matrix for both maps.\n",
    "\n",
    "3. Select one line of the distance matrix, and plot the closests and the farthest point to that line.\n",
    "    \n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebea004d",
   "metadata": {},
   "source": [
    "## Polygon to point"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05ddf869",
   "metadata": {},
   "source": [
    "Let me create some **convex hull**s (polygons):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "838c576f-cc81-4ad1-89e4-8d7361e4fc41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# polygon for each system\n",
    "systems.convex_hull"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef415136",
   "metadata": {},
   "outputs": [],
   "source": [
    "# see them\n",
    "systems.convex_hull.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79ec5f8b",
   "metadata": {},
   "source": [
    "Now, a GDF for the hulls:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c44cbd6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "systems_hulls=systems.convex_hull.to_frame()\n",
    "systems_hulls['system']=['Amazon', 'Parana']\n",
    "systems_hulls.rename(columns={0:'geometry'},inplace=True)\n",
    "systems_hulls=systems_hulls.set_geometry('geometry')\n",
    "systems_hulls.crs=\"EPSG:5641\"\n",
    "systems_hulls"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c7c6472",
   "metadata": {},
   "source": [
    "Next, the distance matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00059e15",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "distanceMatrixKM_sysHull_air=systems_hulls.set_index('system').geometry.apply\\\n",
    "(lambda g: largeAirports.set_index('name').geometry.distance(g)/1000).\\\n",
    "sort_index(axis=0).sort_index(axis=1)\n",
    "\n",
    "distanceMatrixKM_sysHull_air"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aecbc201",
   "metadata": {},
   "source": [
    "All the minimal differences:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1ee6a63",
   "metadata": {},
   "outputs": [],
   "source": [
    "mins=distanceMatrixKM_sysHull_air.idxmin(axis=\"columns\")\n",
    "mins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d4ff09a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting\n",
    "base=systems_hulls.explore()\n",
    "largeAirports[largeAirports.name.isin(mins)].explore(m=base,color='red',marker_kwds=dict(radius=10))\n",
    "largeAirports[~largeAirports.name.isin(mins)].explore(m=base,color='blue',marker_kwds=dict(radius=5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b8e8ffc-55bc-4818-b3b1-e80e52a2123d",
   "metadata": {},
   "source": [
    "### Exercise 3\n",
    "\n",
    "<div class=\"alert-success\">\n",
    "    \n",
    "1. Create a set of points and a set of polygons\n",
    "\n",
    "2. Compute the distance matrix for both sets.\n",
    "\n",
    "3. Select one polygon of the distance matrix, and plot the closests and the farthest point to that polygon.\n",
    "    \n",
    "</div>    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40f859b3",
   "metadata": {},
   "source": [
    "## Distances using _Buffers_\n",
    "\n",
    "A very important case in distance analysis is the use of buffers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66700e80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remember:\n",
    "distanceMatrixKM_riv_air"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85e65bb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting a value (it can be any value)\n",
    "distanceMatrixKM_riv_air.loc['Amazon'].min()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab814d95",
   "metadata": {},
   "source": [
    "We can use any value to create a buffer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77a8d537",
   "metadata": {},
   "outputs": [],
   "source": [
    "minMts=distanceMatrixKM_riv_air.loc['Amazon'].min()*1000\n",
    "\n",
    "#the buffer is a polygon:\n",
    "rivers[rivers.NAME=='Amazon'].buffer(distance = minMts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f670518",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# see buffer:\n",
    "bufferAroundAmazon=rivers[rivers.NAME=='Amazon'].buffer(distance = minMts)\n",
    "bufferAsBase=bufferAroundAmazon.explore(color='red')\n",
    "rivers[rivers.NAME=='Amazon'].explore(m=bufferAsBase,color='blue',style_kwds={'weight':0.5})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4c5369e",
   "metadata": {},
   "source": [
    "Above we used the buffer (red polygon), and the river (blue). Let me add a layer of airports (small ones):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "260d5ea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "small_airports=airports[airports['type']=='small_airport']\n",
    "\n",
    "# plotting\n",
    "rivers[rivers.NAME=='Amazon'].explore(m=bufferAsBase,color='blue',style_kwds={'weight':0.5})\n",
    "small_airports.explore(m=bufferAsBase,color='black')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1298b935",
   "metadata": {},
   "source": [
    "Now, we can use the buffer (polygon) to keep the airports that are at that particular distance around the river:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf9601fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "riversWithinBuffer=small_airports.clip(mask=bufferAroundAmazon)\n",
    "#\n",
    "riversWithinBuffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d87ddd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "bufferAsBase=bufferAroundAmazon.explore(color='red')\n",
    "rivers[rivers.NAME=='Amazon'].explore(m=bufferAsBase,color='blue',style_kwds={'weight':0.5})\n",
    "riversWithinBuffer.explore(m=bufferAsBase,color='black')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92465afd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# minimum of all the minimum by row\n",
    "distanceMatrixKM_riv_air.min(axis=1).min() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40b7f338",
   "metadata": {},
   "outputs": [],
   "source": [
    "# using the previous value\n",
    "minMinMts_5=5*distanceMatrixKM_riv_air.min(axis=1).min()*1000\n",
    "\n",
    "\n",
    "allMinBuffer=rivers.buffer(distance = minMinMts_5).explore(color='red')\n",
    "rivers.explore(m=allMinBuffer,color='blue',style_kwds={'weight':0.5})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73543dc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# you see all the buffer polygons:\n",
    "riversAll_buf=rivers.buffer(distance = minMinMts_5)\n",
    "riversAll_buf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3d6f11a-ec5f-4028-bd3e-bf4cec827168",
   "metadata": {},
   "source": [
    "Now keep small airports in buffer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36e5d5a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "allRiversWithinBuffs=small_airports.clip(riversAll_buf)\n",
    "allRiversWithinBuffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0407b593",
   "metadata": {},
   "outputs": [],
   "source": [
    "# simple\n",
    "base=riversAll_buf.plot(color='yellow')\n",
    "allRiversWithinBuffs.plot(ax=base, color='green', markersize=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3df7ac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# folium\n",
    "\n",
    "base=riversAll_buf.explore(color='yellow')\n",
    "allRiversWithinBuffs.explore(m=base, color='green')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "323d59e5-3623-4723-81be-f9dbb3cead1a",
   "metadata": {},
   "source": [
    "### Exercise 4\n",
    "\n",
    "<div class=\"alert-success\">\n",
    "    \n",
    "1. Create a set of points and a set of lines\n",
    "\n",
    "2. Get the buffer for the lines, select different values for the distance.\n",
    "\n",
    "3. Keep the points that are within the buffer (as in point 2, you need to play with differn distances until you show something interesting.  \n",
    "    \n",
    "</div>   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae6c03fb-08dc-42d2-999c-ef1315ddb32f",
   "metadata": {},
   "source": [
    "# Using data from spatial objects\n",
    "\n",
    "This is time to use  *dataPeru_indicadores.xlsx* file and the  map of Peruvian districts: *DistritosMap.zip* (zipped shape file).\n",
    "\n",
    "Let's read the data in :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cad54a69-3198-4ae0-b561-b786dc0c4c58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data table\n",
    "import pandas as pd\n",
    "\n",
    "peruData=os.path.join(\"data\",\"dataPeru_indicadores.xlsx\")\n",
    "datadis=pd.read_excel(peruData,\n",
    "                     dtype={'Ubigeo': object})\n",
    "datadis.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a840636-49ab-4a6d-9bb6-0e344822e3e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# map\n",
    "import geopandas as gpd\n",
    "\n",
    "peruDataDist=os.path.join(\"maps\",\"DistritosMap.zip\")\n",
    "\n",
    "datadismap=gpd.read_file(peruDataDist)\n",
    "\n",
    "datadismap.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e234648d-afd8-49b0-9af6-f02e23461d82",
   "metadata": {},
   "source": [
    "Next we will merge the indicators table into the map."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4de5282-8a5b-45d8-9ced-6c3690a15b42",
   "metadata": {},
   "source": [
    "## Merging\n",
    "\n",
    "When merging, verify the amount of resulting rows first:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d0789a7-be19-4eb2-a5d0-66aae882a93f",
   "metadata": {},
   "outputs": [],
   "source": [
    "datadismap.merge(datadis, left_on='DISTRITO', right_on='Distrito').shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42b0ed6e-263d-4b59-9399-4626d13d04c0",
   "metadata": {},
   "source": [
    "That is totally wrong. Let's check:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "270aca3a-7b1d-453a-89d6-15d821cf135f",
   "metadata": {},
   "outputs": [],
   "source": [
    "datadis.Distrito"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b84f387-45a7-4fb5-a999-ab62f3842845",
   "metadata": {},
   "outputs": [],
   "source": [
    "datadismap.DISTRITO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f76ed070-616f-4199-a6b0-48f1c80abff6",
   "metadata": {},
   "source": [
    "The amount of rows is the same when separate, but increases when merged. \n",
    "\n",
    "Let's do some preprocessing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d21b724-8212-4bed-88c9-fa9858330f56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all capitals, no empty spaces before or after.\n",
    "\n",
    "capitalizeColumns=lambda x: x.str.upper().str.strip()\n",
    "datadis[['Provincia','Distrito']]=datadis[['Provincia','Distrito']].apply(capitalizeColumns)\n",
    "datadismap[['PROVINCIA','DISTRITO']]=datadismap[['PROVINCIA','DISTRITO']].apply(capitalizeColumns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ce410db-12e2-405a-83e2-0bf822da1c48",
   "metadata": {},
   "source": [
    "The names from non-english speaking countries may come with some symbols that may cause trouble (', ~). Let's get rid of those:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aebbfce-ff05-4b8d-938a-c8c50a21d798",
   "metadata": {},
   "outputs": [],
   "source": [
    "import unidecode\n",
    "\n",
    "\n",
    "byePunctuation=lambda x: unidecode.unidecode(x)\n",
    "datadis[['Provincia','Distrito']]=datadis[['Provincia','Distrito']].map(byePunctuation)  #applymap for olderpandas\n",
    "datadismap[['PROVINCIA','DISTRITO']]=datadismap[['PROVINCIA','DISTRITO']].map(byePunctuation) #applymap for olderpandas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d744c9a9-fd9c-4138-b135-4f7d675354ae",
   "metadata": {},
   "source": [
    "Are the name of the districts unique?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c33a551-51a1-4225-86a6-b6d9ae27b12f",
   "metadata": {},
   "outputs": [],
   "source": [
    "datadis.Distrito.duplicated().sum(),datadismap.DISTRITO.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8d3ae42-d0ed-4e6c-a114-3517b2351216",
   "metadata": {},
   "source": [
    "The presence of duplicates, forces we create  a column of unique values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50782d60-96b3-4fda-8731-a236a45d8216",
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatenating\n",
    "datadis['provDist']=[\"+\".join(pd) for pd in zip (datadis.Provincia,datadis.Distrito)]\n",
    "datadismap['provDist']=[\"+\".join(pd) for pd in zip (datadismap.PROVINCIA,datadismap.DISTRITO)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca51a1a7-9979-4837-b042-4bc7baffbcc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the new column looks like this:\n",
    "datadis['provDist'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8e8beee-a625-4ccc-95f1-a39463925166",
   "metadata": {},
   "source": [
    "It would be good making sure no *ghost* appears between words:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3479f982-f55e-4e0c-90ba-ed855f10459b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# replacing dashes and multiple spaces by a simple space\n",
    "datadis['provDist']=datadis.provDist.str.replace(\"\\-|\\_|\\s+\",\" \",regex=True)\n",
    "datadismap['provDist']=datadismap.provDist.str.replace(\"\\-|\\_|\\s+\",\" \",regex=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43aaa1a8-f47d-474c-b465-bada8c5fb40d",
   "metadata": {},
   "source": [
    "Let's find out what is NOT matched between the  tables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25ed7646-6dbd-488f-9445-798c3d33d1b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "nomatch_df=set(datadis.provDist)- set(datadismap.provDist)\n",
    "nomatch_gdf=set(datadismap.provDist)-set(datadis.provDist) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29b8fc82-e9b9-412c-801d-fa0ce0f5f27f",
   "metadata": {},
   "source": [
    "This is what could not be matched:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e958add0-261c-42d4-94ca-fc81ad5a1be4",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(nomatch_df), len(nomatch_gdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dc7a671-ccfa-43e9-99c7-61a44f54fccf",
   "metadata": {},
   "source": [
    "Let's try renaming the districts using **fuzzy merging**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87f6e31a-35da-4cc9-a92c-c1cb1ea09313",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pick the closest match from nomatch_gdf for a value in nomatch_df\n",
    "from thefuzz import process\n",
    "[(dis,process.extractOne(dis,nomatch_gdf)) for dis in sorted(nomatch_df)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13ba7847-e9b3-47fe-9a65-9e93472eddc3",
   "metadata": {},
   "source": [
    "If you are comfortable, you prepare a _dictionary_ of changes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a892fedc-0d65-46bf-9f99-73dc01e409c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# is this OK?\n",
    "{dis:process.extractOne(dis,nomatch_gdf)[0] for dis in sorted(nomatch_df)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f75bd1d5-0a73-4ac7-98e0-6f3282bbc635",
   "metadata": {},
   "outputs": [],
   "source": [
    "# then:\n",
    "changesDis_df={dis:process.extractOne(dis,nomatch_gdf)[0] for dis in sorted(nomatch_df)}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9a2d81f-93eb-4f2f-b7ec-32faac5be6c0",
   "metadata": {},
   "source": [
    "Now, make the replacements:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5b7b379-d869-405b-9593-c37afa881943",
   "metadata": {},
   "outputs": [],
   "source": [
    "datadis.provDist.replace(changesDis_df,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "352c78fe-1b57-474b-b30a-0c7cea12ea4e",
   "metadata": {},
   "source": [
    "Now the merge can happen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48835a7d-b7ea-47e3-b96d-720520109d8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "datadisMap=datadismap.merge(datadis, on='provDist')\n",
    "# check\n",
    "datadisMap.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1919efb-07bd-4e54-95e7-7a9f4f4e4515",
   "metadata": {},
   "outputs": [],
   "source": [
    "bye=['Departamento', 'Provincia', 'Distrito','INSTITUCIO','provDist']\n",
    "datadisMap.drop(columns=bye,inplace=True)\n",
    "\n",
    "# keeping\n",
    "datadisMap.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "674d3588-fc76-459e-b24d-4b48346060b0",
   "metadata": {},
   "source": [
    "### Exercises Part II\n",
    "\n",
    "<div class=\"alert-warning\">\n",
    "    \n",
    "Exercises 5,6,7,8, and 9 for this part must read you data from GitHub links, and the coding and results must be published using GitHub Pages. This is a different project, so those exercises will be published in a different webpage.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "970a0c9c-6318-4c4f-a476-d0ed7e9d916d",
   "metadata": {},
   "source": [
    "### Exercise 5\n",
    "\n",
    "<div class=\"alert-success\">\n",
    "    \n",
    "1. Get a polygons map of the lowest administrative unit possible.\n",
    "    \n",
    "2. Get a table of variables for those units. At least 3 numerical variables.\n",
    "\n",
    "3. Preprocess both tables and get them ready for merging.\n",
    "\n",
    "4. Do the merging, making the changes needed so that you keep the most columns.\n",
    "    \n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4944a216-12d8-423c-9461-ea8a28c06c69",
   "metadata": {},
   "source": [
    "## Exploring one variable\n",
    "\n",
    "This time, we explore statistically one variable in the map:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26d813c9-d01d-40f4-b284-57e9a87e41b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# statistics\n",
    "datadisMap.IDH2019.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c75d39e-f2b9-4c7d-9104-eaf64bf70413",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sea\n",
    "\n",
    "sea.histplot(datadisMap.IDH2019, color='yellow')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1610d9ba-1fb6-4fdc-9b9c-cecd9810c1dc",
   "metadata": {},
   "source": [
    "Notice the histogram divides the data in intervals which are the base of the bars. Seaborn uses the [Freedman-Diaconis](https://en.wikipedia.org/wiki/Freedman%E2%80%93Diaconis_rule) formula to compute the bins.\n",
    "\n",
    "Let's see other possibilities, but please install [**numba**](https://numba.readthedocs.io/en/stable/user/installing.html) before runing the next code; also make sure you have **pysal**, **mapclassify** and **numpy** installed: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96038d66-2187-49da-bffa-2930cda7a889",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mapclassify \n",
    "import numpy as np\n",
    "\n",
    "np.random.seed(12345) # so we all get the same results!\n",
    "\n",
    "# let's try 5 intervals\n",
    "K=5\n",
    "theVar=datadisMap['IDH2019']\n",
    "# same interval width, easy interpretation\n",
    "ei5 = mapclassify.EqualInterval(theVar, k=K)\n",
    "# same interval width based on standard deviation, easy - but not as the previous one, poor when high skewness\n",
    "msd = mapclassify.StdMean(theVar)\n",
    "# interval width varies, counts per interval are close, not easy to grasp, repeated values complicate cuts                                \n",
    "q5=mapclassify.Quantiles(theVar,k=K)\n",
    "\n",
    "# based on similarity, good for multimodal data \n",
    "mb5 = mapclassify.MaximumBreaks(theVar, k=K)\n",
    "# based on similarity, good for skewed data\n",
    "ht = mapclassify.HeadTailBreaks(theVar) # no K needed\n",
    "# based on similarity, optimizer\n",
    "fj5 = mapclassify.FisherJenks(theVar, k=K)\n",
    "# based on similarity, optimizer\n",
    "jc5 = mapclassify.JenksCaspall(theVar, k=K)\n",
    "# based on similarity, optimizer\n",
    "mp5 = mapclassify.MaxP(theVar, k=K)   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f45a91b-90d0-4425-a428-e8cc7c4b5249",
   "metadata": {},
   "source": [
    "How can we select the right classification?\n",
    "\n",
    "Let me use the the **absolute deviation around class median** (ADCM) to make the comparisson:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da6348ea-f788-41eb-a213-bf855e47b030",
   "metadata": {},
   "outputs": [],
   "source": [
    "class5 = q5, ei5,msd, ht, mb5, fj5, jc5, mp5\n",
    "# Collect ADCM for each classifier\n",
    "fits = np.array([ c.adcm for c in class5])\n",
    "# Convert ADCM scores to a DataFrame\n",
    "adcms = pd.DataFrame(fits)\n",
    "# Add classifier names\n",
    "adcms['Classifier'] = [c.name for c in class5]\n",
    "\n",
    "# see the value\n",
    "adcms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "049bb308-b855-4688-89e9-0a8c32c1d3d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename\n",
    "adcms.rename(columns = {0:'ADCM'},inplace=True)\n",
    "\n",
    "# reorder and plot\n",
    "adcms=adcms.sort_values('ADCM').reset_index()\n",
    "sea.barplot(y='Classifier',\n",
    "    hue='Classifier', x='ADCM', data=adcms, palette='Pastel1'\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e9cfb4f-d19a-4bbe-9f88-ea4c2819182d",
   "metadata": {},
   "source": [
    "Let's keep the the scheme with the lowest  ADCM:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45cb7520-a78c-4212-90b8-03633853c75c",
   "metadata": {},
   "outputs": [],
   "source": [
    "datadisMap['IDH_jc5'] = jc5.yb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2628ba61-afe8-468a-9dfc-9457a9d13d36",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "f, ax = plt.subplots(1, figsize=(9, 9))\n",
    "datadisMap.plot(column='IDH_jc5', \n",
    "        cmap='viridis', \n",
    "        categorical=True,\n",
    "        edgecolor='white', \n",
    "        linewidth=0., \n",
    "        alpha=0.75, \n",
    "        legend=True,\n",
    "        legend_kwds=dict(loc=2),\n",
    "        ax=ax\n",
    "       )\n",
    "\n",
    "ax.set_axis_off()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "035e49c6-b49d-47bc-89d1-ef3f394dcabd",
   "metadata": {},
   "source": [
    "Notice the **geopandas.plot()** can also use those schemes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec3b6826-aba0-492f-9dfe-d0adc9d153ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(1, figsize=(9, 9))\n",
    "datadisMap.plot(column='IDH2019', \n",
    "        cmap='viridis',       \n",
    "        scheme='JenksCaspall',\n",
    "        k=5, \n",
    "        edgecolor='white', \n",
    "        linewidth=0., \n",
    "        alpha=0.75, \n",
    "        legend=True,\n",
    "        legend_kwds=dict(loc=2),\n",
    "        ax=ax\n",
    "       )\n",
    "\n",
    "ax.set_axis_off()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3415d594-7ffb-4fb3-94e3-29e2b42cf8a2",
   "metadata": {},
   "source": [
    "Notice some details on the result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18f9e06c-c1dd-4c3a-991e-75b1f33b5bd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we got\n",
    "jc5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1651287d-0b06-481b-ab6a-b159ef3d36f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# group label\n",
    "np.unique(jc5.yb,return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d6d749a-2ebe-4b2d-a319-49ef57c5d80e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# jc5.yb into a pandas Series\n",
    "\n",
    "pd.Series(jc5.yb).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb53b2ee-27f3-478d-9f17-0562558f5cdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# these are the cuts, but it is not including the min value\n",
    "jc5.bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19e8598d-981a-448d-b59b-74b198c706c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# completing the bins\n",
    "jc5_bins=list(jc5.bins)\n",
    "jc5_bins.insert(0,datadisMap.IDH2019.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb2d0d8e-50fe-41b0-b086-500bdc2cf0aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "sea.histplot(datadisMap.IDH2019, bins=jc5_bins,color='yellow')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd3779c7-b764-44c5-b703-cea6fc907177",
   "metadata": {},
   "source": [
    "### Exercise 6\n",
    "\n",
    "<div class=\"alert-success\">\n",
    "    \n",
    "1. Choose a numeric variable from your merged data.\n",
    "2. Decide which is the  best classification scheme for that variable.\n",
    "3. Make a map for the best scheme.\n",
    "4. Make a histogram for the best scheme.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acb9ee6b-4c2f-4944-8021-b312bd0036d7",
   "metadata": {},
   "source": [
    "## Neighborhood\n",
    "\n",
    "We can compute the neighborhood for each object in a map using different algorithms:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86843321-186e-4802-aba4-3e91a6b1b14f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from libpysal.weights import Queen, Rook, KNN\n",
    "\n",
    "# rook\n",
    "w_rook = Rook.from_dataframe(datadisMap,use_index=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb99fe0e-1653-4bc7-b999-89ad9d6db6b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# queen\n",
    "w_queen = Queen.from_dataframe(datadisMap,use_index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfb5474b-da2d-436e-8e76-a4ba23149635",
   "metadata": {},
   "outputs": [],
   "source": [
    "# k nearest neighbors\n",
    "w_knn = KNN.from_dataframe(datadisMap, k=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20a34f9f-ba61-42fe-b6ea-d1f33b536920",
   "metadata": {},
   "source": [
    "Let's understand the differences:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d731009a-8404-4f55-bcf0-c392e448dd24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# first district in the GDF:\n",
    "datadisMap.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f0c2161-2d95-49f9-b6b6-edef8be67895",
   "metadata": {},
   "outputs": [],
   "source": [
    "# amount of neighbors of that district\n",
    "len(w_rook.neighbors[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a26e817-e6b4-4e52-a8ac-5ff1409d6ae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# details\n",
    "datadisMap.iloc[w_rook.neighbors[0],]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0070510f-20cb-4251-a91b-d7fe14eb6563",
   "metadata": {},
   "outputs": [],
   "source": [
    "# see the neighbor\n",
    "datadisMap.iloc[w_rook.neighbors[0] ,].plot(facecolor=\"yellow\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2533f22-607c-4357-98d8-b5d11bb100d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# see whole area\n",
    "base=datadisMap[datadisMap.PROVINCIA==\"TACNA\"].plot()\n",
    "datadisMap.iloc[w_rook.neighbors[0] ,].plot(ax=base,facecolor=\"yellow\",edgecolor='k')\n",
    "datadisMap.head(1).plot(ax=base,facecolor=\"red\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a85f104-870c-41f1-9d38-3a8c60735556",
   "metadata": {},
   "source": [
    "Let's do the same with queen neighbors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff41c1e4-b3e5-4bf8-8e71-f324b0359a0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# how many\n",
    "len(w_queen.neighbors[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96c1d332-ee6f-4618-96c0-1fe9ece97e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# details\n",
    "datadisMap.iloc[w_queen.neighbors[0] ,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76585272-7591-4b48-b9df-e057995011bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# see\n",
    "datadisMap.iloc[w_queen.neighbors[0] ,].plot(facecolor=\"yellow\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57a6bda9-5af0-4245-92ce-dc6e8f9b9aed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# whole area\n",
    "base=datadisMap[datadisMap.PROVINCIA==\"TACNA\"].plot()\n",
    "datadisMap.iloc[w_queen.neighbors[0] ,].plot(ax=base,facecolor=\"yellow\",edgecolor='k')\n",
    "datadisMap.head(1).plot(ax=base,facecolor=\"red\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "2a19db2d-7613-487f-a550-18255fe231f3",
   "metadata": {},
   "source": [
    "What about the _four_ closest ones?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbfa0517-5f72-4c1f-817b-c1df6a4bfaf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "w_knn.neighbors[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e67397df-57e1-4d0e-9a19-30717eec3eca",
   "metadata": {},
   "outputs": [],
   "source": [
    "base=datadisMap[datadisMap.PROVINCIA==\"TACNA\"].plot()\n",
    "datadisMap.iloc[w_knn.neighbors[0],].plot(ax=base,facecolor=\"yellow\")\n",
    "datadisMap.head(1).plot(ax=base,facecolor=\"red\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd23b4aa-1110-4743-a658-065cd8c925f9",
   "metadata": {},
   "source": [
    "### Exercise 7\n",
    "\n",
    "<div class=\"alert-success\">\n",
    "        \n",
    "Compute the neighbors of the capital of your country. Plot the results for each of the options.\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b1899e2-554d-41ce-b38b-0830802ccaae",
   "metadata": {},
   "source": [
    "## Spatial correlation\n",
    "\n",
    "We need the neighboorhood matrix (the weight matrix) to compute spatial correlation: if the variable value is correlated with the values of its neighbors - which proves a spatial effect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59143e63-f478-419e-a84a-3617f5c6fc90",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(*w_knn.full()) # 1 means both are neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b103792-bf59-4965-bf9a-17d51be8b49b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# needed for spatial correlation\n",
    "w_knn.transform = 'R'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a57356f5-5d92-48e7-b135-12ce0e0ea09d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(*w_knn.full()).head(12) # 1 means both are neighbors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dab308c8-26ad-45bb-aa05-5462cd07fc5c",
   "metadata": {},
   "source": [
    "Spatial correlation is measured by the Moran's I statistic:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7aaedad-e443-407c-9146-3b87c94f237c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from esda.moran import Moran\n",
    "\n",
    "moranIDH = Moran(datadisMap['IDH2019'], w_knn)\n",
    "moranIDH.I,moranIDH.p_sim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f17dab87-7709-405e-afbe-605e10688d18",
   "metadata": {},
   "source": [
    "A significant Moran's I suggest spatial correlation. Let's see the spatial scatter plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f69e7e5-a4d8-4d31-be91-f295cfb19f68",
   "metadata": {},
   "outputs": [],
   "source": [
    "from splot.esda import moran_scatterplot\n",
    "\n",
    "fig, ax = moran_scatterplot(moranIDH, aspect_equal=True)\n",
    "ax.set_xlabel('IDH_std')\n",
    "ax.set_ylabel('SpatialLag_IDH_std');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03ccfa77-4bc2-41b0-95d4-7bf743cac51a",
   "metadata": {},
   "source": [
    "### Exercise 8\n",
    "\n",
    "<div class=\"alert-success\">\n",
    "    \n",
    "1. Compute the Moran's coefficient for **all** your numeric variables.\n",
    "    \n",
    "2. Make a scatter plot for each variable.\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b6a56a5-c9ff-4642-9e57-a98b9195c867",
   "metadata": {},
   "source": [
    "### Local Spatial Correlation\n",
    "\n",
    "We can compute a LISA (local Moran) for each case. That will help us find spatial clusters (spots) and spatial outliers:\n",
    "\n",
    "* A **hotSpot** is a polygon whose value in the variable is high AND is surrounded with polygons with also high values.\n",
    "\n",
    "* A **coldSpot** is a polygon whose value in the variable is low AND is surrounded with polygons with also low values.\n",
    "\n",
    "* A **coldOutlier** is a polygon whose value in the variable is low BUT is surrounded with polygons with  high values.\n",
    "\n",
    "* A **hotOutlier** is a polygon whose value in the variable is high BUT is surrounded with polygons with  low values.\n",
    "\n",
    "It is also possible that no significant correlation is detected. Let's see those values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de5eaddb-439a-45af-9ca4-c2a833576c2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The scatterplot with local info\n",
    "from esda.moran import Moran_Local\n",
    "\n",
    "# calculate Moran_Local and plot\n",
    "lisaIDH = Moran_Local(y=datadisMap['IDH2019'], w=w_knn,seed=2022)\n",
    "fig, ax = moran_scatterplot(lisaIDH,p=0.05)\n",
    "ax.set_xlabel('IDH_std')\n",
    "ax.set_ylabel('SpatialLag_IDH_std');\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e5ee422-356e-472a-ba16-7a09f1daeefc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the map with the spots and outliers\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from splot.esda import lisa_cluster\n",
    "f, ax = plt.subplots(1, figsize=(12, 12))\n",
    "plt.title('Spots and Outliers')\n",
    "fig = lisa_cluster(lisaIDH, \n",
    "                   datadisMap,ax=ax,\n",
    "                   legend_kwds={'loc': 'center left', \n",
    "                                'bbox_to_anchor': (0.7, 0.6)});\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5acf306-b47c-4914-b050-e2a32b5ad43a",
   "metadata": {},
   "source": [
    "Let me add that data to my gdf:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b627cccc-7123-45a0-ba53-9f661bac77f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# quadrant\n",
    "lisaIDH.q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2832b12c-8b33-4363-b0b9-7eb0fa1aa482",
   "metadata": {},
   "outputs": [],
   "source": [
    "# significance\n",
    "lisaIDH.p_sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9bedff6-0276-42e5-bc60-118274bf0151",
   "metadata": {},
   "outputs": [],
   "source": [
    "# quadrant: 1 HH,  2 LH,  3 LL,  4 HL\n",
    "pd.Series(lisaIDH.q).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad08c195-9c11-4e38-925f-42aa620a8f9c",
   "metadata": {},
   "source": [
    "The info in **lisaIDH.q** can not be used right away, we need to add if the local spatial correlation is significant:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b24bb3f7-49c0-4fca-9d36-4b19bf512ac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "datadisMap['IDH_quadrant']=[l if p <0.05 else 0 for l,p in zip(lisaIDH.q,lisaIDH.p_sim)  ]\n",
    "datadisMap['IDH_quadrant'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0b86cd7-af02-4667-8cdc-adbcacf236c8",
   "metadata": {},
   "source": [
    "Now, we recode:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4e05f70-16d3-4be1-8fd7-89b6be715f00",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [ '0 no_sig', '1 hotSpot', '2 coldOutlier', '3 coldSpot', '4 hotOutlier']\n",
    "\n",
    "datadisMap['IDH_quadrant_names']=[labels[i] for i in datadisMap['IDH_quadrant']]\n",
    "\n",
    "datadisMap['IDH_quadrant_names'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54771dcd-a7b6-4429-bd49-3e785f2dd1ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import colors\n",
    "myColMap = colors.ListedColormap([ 'white', 'pink', 'cyan', 'azure','red'])\n",
    "\n",
    "\n",
    "\n",
    "# Set up figure and ax\n",
    "f, ax = plt.subplots(1, figsize=(12,12))\n",
    "# Plot unique values choropleth including\n",
    "# a legend and with no boundary lines\n",
    "\n",
    "plt.title('Spots and Outliers')\n",
    "\n",
    "datadisMap.plot(column='IDH_quadrant_names', \n",
    "                categorical=True,\n",
    "                cmap=myColMap,\n",
    "                linewidth=0.1, \n",
    "                edgecolor='k',\n",
    "                legend=True,\n",
    "                legend_kwds={'loc': 'center left', \n",
    "                             'bbox_to_anchor': (0.7, 0.6)},\n",
    "                ax=ax)\n",
    "# Remove axis\n",
    "ax.set_axis_off()\n",
    "# Display the map\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf1b9f05-a42d-4360-b403-3934344d4327",
   "metadata": {},
   "source": [
    "### Exercise 9\n",
    "\n",
    "<div class=\"alert-success\">\n",
    "    \n",
    "1. Compute the Local Moran for the variables in your data that have significant spatial correlation.\n",
    "    \n",
    "2. Create a new column for each of those variables, with a label ('0 no_sig', '1 hotSpot', '2 coldOutlier', '3 coldSpot', '4 hotOutlier').\n",
    "\n",
    "3. Prepare a map for each of the variables analyzed, showing the spots and outliers.\n",
    "    \n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
